#自定义数据源路径
custom.hbase.path="com.hailian.scala.hbase.org.custom.spark.sql.hbase"

#配置spark相关参数
spark.worker.timeout="500"
spark.rpc.askTimeout="600s"
spark.network.timeoout="600s"
spark.task.maxFailures="5"
spark.speculation.bool="true"
spark.driver.allowMutilpleContext="true"
spark.serializer="org.apache.spark.serializer.KryoSerializer"
//spark.streaming.checkpointdir="hdfs://cdh-node01:9000/streaming"
spark.streaming.kafka.maxRatePerPartition="2"
#因为首次启动JOB的时候，由于冷启动会造成内存使用太大，为了防止这种情况出现，限制首次处理的数据量
spark.streaming.backpressure.enabled="true"
spark.streaming.backpressure.initialRate="10"
enableSendEmailOnTaskFail="true"
spark.buffer.pageSize="16m"
spark.streaming.backpressure.pid.minRate="10"
spark.speculation.interval=300
spark.speculation.quantile=0.9
test.value="Hlb-common"
test1.value="Hlb-common.test1"
